{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiffPASS â€“ Example usage on prokaryotic datasets\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib\n",
    "from collections.abc import Sequence\n",
    "from typing import Optional\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# DiffPASS imports\n",
    "from diffpass.train import InformationAndReciprocalBestHits, compute_num_correct_matchings\n",
    "from diffpass.msa_parsing import read_msa\n",
    "from diffpass.data_utils import generate_dataset, dataset_tokenizer\n",
    "\n",
    "\n",
    "# Set the number of threads for PyTorch\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\n",
    "    f\"cuda{(':' + input('Enter the CUDA device number:')) if torch.cuda.device_count() > 1 else ''}\"\n",
    "    if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one of the two prokaryotic datasets: HK-RR and MALG-MALK.\n",
    "\n",
    "`get_species_name` extracts species names from the FASTA header.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROKARYOTIC DATASETS\n",
    "\n",
    "msa_data = [\n",
    "    read_msa(\"data/HK-RR/HK_in_Concat_nnn.fasta\", -1),\n",
    "    read_msa(\"data/HK-RR/RR_in_Concat_nnn.fasta\", -1)\n",
    "]\n",
    "get_species_name = lambda header: header.split(\"|\")[1]\n",
    "\n",
    "# msa_data = [\n",
    "#     read_msa(\"data/MALG-MALK/MALG_cov75_hmmsearch_extr5000_withLast_b.fasta\", -1),\n",
    "#     read_msa(\"data/MALG-MALK/MALK_cov75_hmmsearch_extr5000_withLast_b.fasta\", -1)\n",
    "# ]\n",
    "# get_species_name = lambda header: header.split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dataset = {\n",
    "    \"N\": 500,  # Average number of sequences in the input\n",
    "    \"pos\": 0,  # Size of the context pairs to use as positive example \n",
    "    \"max_size\": 100,  # Max size of species MSAs (if same as N there is no limit on size)\n",
    "    \"NUMPY_SEED\": 10,\n",
    "    \"NUMPY_SEED_OTHER\": 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, group_sizes = generate_dataset(\n",
    "    parameters_dataset, msa_data, get_species_name=get_species_name\n",
    ")\n",
    "tokenized_dataset = dataset_tokenizer(dataset, device=DEVICE)\n",
    "x, y = tokenized_dataset[\"msa\"][\"left\"], tokenized_dataset[\"msa\"][\"right\"]\n",
    "\n",
    "n_seqs = len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairings using DiffPASS's `InformationAndReciprocalBestHits` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SEED = 100\n",
    "torch.manual_seed(TORCH_SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for soft permutations (Gumbel-Sinkhorn)\n",
    "permutation_cfg = {\n",
    "    \"tau\": torch.tensor(1e-2),\n",
    "    \"n_iter\": 10,\n",
    "    \"noise\": False,\n",
    "}\n",
    "\n",
    "# Information-theoretic part of the loss: whether we use two-body entropy or mutual information\n",
    "information_measure = \"TwoBodyEntropy\"\n",
    "\n",
    "# Settings affecting the reciprocal best hits part of the loss\n",
    "similarity_kind = \"Hamming\"\n",
    "similarities_cfg = {\n",
    "    \"use_dot\": False,\n",
    "    \"p\": 1\n",
    "}\n",
    "reciprocal_best_hits_cfg = {\n",
    "    \"tau\": torch.tensor(1e-1)\n",
    "}\n",
    "inter_group_loss_score_fn = torch.nn.CosineSimilarity(dim=-1)\n",
    "intra_group_loss_score_fn = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "# Loss weights\n",
    "loss_weights_rbh = {\n",
    "    information_measure: 1.,\n",
    "    \"ReciprocalBestHits\": 1.,\n",
    "}\n",
    "loss_weights_mt = {\n",
    "    information_measure:1.,\n",
    "    \"Mirrortree\": 0.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "fit_cfg = {\n",
    "    \"epochs\": 1,\n",
    "    \"optimizer_name\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\"lr\": 1e-1, \"weight_decay\": 0.},\n",
    "    \"mean_centering\": True,\n",
    "    # \"similarity_gradient_bypass\": False,\n",
    "    \"show_pbar\": False,\n",
    "    \"compute_final_soft\": False\n",
    "}\n",
    "\n",
    "ipa_cfg = {\n",
    "    \"n_start\": 20,\n",
    "    \"n_end\": None,\n",
    "    \"max_iters\": 1,\n",
    "    \"compute_correct_index_based\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    *,\n",
    "    group_sizes: Sequence[int],\n",
    "    n_start: int,\n",
    "    n_end: Optional[int],\n",
    "    max_iters: int,\n",
    "    compute_correct_index_based: bool,\n",
    "    show_pbar: bool = True,\n",
    "):\n",
    "    def create_dpass():\n",
    "        return InformationAndReciprocalBestHits(\n",
    "            group_sizes=group_sizes,\n",
    "            fixed_matchings=fixed_matchings,\n",
    "            loss_weights=loss_weights_rbh,\n",
    "            # loss_weights=loss_weights_mt,\n",
    "            permutation_cfg=permutation_cfg,\n",
    "            information_measure=information_measure,\n",
    "            similarity_kind=similarity_kind,\n",
    "            similarities_cfg=similarities_cfg,\n",
    "            reciprocal_best_hits_cfg=reciprocal_best_hits_cfg,\n",
    "            inter_group_loss_score_fn=inter_group_loss_score_fn,\n",
    "            # intra_group_loss_score_fn=intra_group_loss_score_fn\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    n_seqs = len(x)\n",
    "    n_groups = len(group_sizes)\n",
    "    offsets = torch.from_numpy(np.repeat(np.cumsum([0] + list(group_sizes))[:-1], repeats=group_sizes))\n",
    "    group_idxs = torch.from_numpy(np.repeat(np.arange(n_groups), repeats=group_sizes))\n",
    "\n",
    "    if n_end is None:\n",
    "        n_end = n_seqs\n",
    "\n",
    "    # Initial fit with no fixed matchings\n",
    "    fixed_matchings = None\n",
    "    dpass = create_dpass()\n",
    "    results = dpass.fit(x, y, **fit_cfg)\n",
    "    hard_losses_identity_perm = results.hard_losses_identity_perm\n",
    "    hard_losses_this_step = {\n",
    "        k: (results.hard_losses[k][0], results.hard_losses[k][-1])\n",
    "        for k in results.hard_losses\n",
    "    }\n",
    "    correct_this_step = compute_num_correct_matchings(\n",
    "        results, index_based=compute_correct_index_based\n",
    "    )\n",
    "    hard_perms = [results.hard_perms]\n",
    "    hard_losses = [hard_losses_this_step]\n",
    "    correct = [correct_this_step]\n",
    "\n",
    "    # Subsequent fits: at a given iteration we use fixed matchings chosen from the results of the\n",
    "    # previous iteration\n",
    "    pbar = list(range(n_start, n_end))\n",
    "    pbar = tqdm(pbar) if show_pbar else pbar\n",
    "    for N in pbar:\n",
    "        for it in range(max_iters):\n",
    "            mapped_idxs = offsets + torch.cat(results.hard_perms[1])\n",
    "            rand_fixed_idxs = torch.randperm(n_seqs)[:N]\n",
    "            rand_fixed_idxs = torch.sort(rand_fixed_idxs).values\n",
    "            rand_mapped_idxs = mapped_idxs[rand_fixed_idxs]\n",
    "            rand_group_idxs = group_idxs[rand_fixed_idxs]\n",
    "            rand_fixed_rel_idxs = rand_fixed_idxs - offsets[rand_fixed_idxs]\n",
    "            rand_mapped_rel_idxs = rand_mapped_idxs - offsets[rand_mapped_idxs]\n",
    "    \n",
    "            fixed_matchings = [[] for _ in range(n_groups)]\n",
    "            for rand_group_idx, mapped_rel_idx, fixed_rel_idx in zip(\n",
    "                    rand_group_idxs, rand_mapped_rel_idxs, rand_fixed_rel_idxs\n",
    "            ):\n",
    "                fixed_matchings[rand_group_idx].append(\n",
    "                    (mapped_rel_idx.item(), fixed_rel_idx.item())\n",
    "                )\n",
    "    \n",
    "            dpass = create_dpass()\n",
    "            results = dpass.fit(x, y, **fit_cfg)\n",
    "    \n",
    "        hard_losses_this_step = {\n",
    "            k: (results.hard_losses[k][0], results.hard_losses[k][-1])\n",
    "            for k in results.hard_losses\n",
    "        }\n",
    "        correct_this_step = compute_num_correct_matchings(\n",
    "            results, index_based=compute_correct_index_based\n",
    "        )\n",
    "        hard_perms.append(results.hard_perms)\n",
    "        hard_losses.append(hard_losses_this_step)\n",
    "        correct.append(correct_this_step)\n",
    "\n",
    "    return {\n",
    "        \"hard_perms\": hard_perms,\n",
    "        \"hard_losses\": hard_losses,\n",
    "        \"correct\": correct,\n",
    "        \"hard_losses_identity_perm\": hard_losses_identity_perm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_results = optimize(\n",
    "    x, y,\n",
    "    group_sizes=group_sizes,\n",
    "    **ipa_cfg\n",
    ")\n",
    "\n",
    "hard_losses = ipa_results[\"hard_losses\"]\n",
    "correct = ipa_results[\"correct\"]\n",
    "hard_losses_identity_perm = ipa_results[\"hard_losses_identity_perm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in hard_losses[0]:\n",
    "    plt.plot([l[key][0] for l in hard_losses], \".-\", label=\"start\")\n",
    "    plt.plot([l[key][1] for l in hard_losses], \".-\", label=\"end\")\n",
    "    plt.axhline(hard_losses_identity_perm[key])\n",
    "    plt.legend()\n",
    "    plt.title(f\"{key} loss\")\n",
    "    plt.show()\n",
    "\n",
    "plt.plot([c[0] / n_seqs for c in correct], \".-\", label=\"start\")\n",
    "plt.plot([c[1] / n_seqs for c in correct], \".-\", label=\"end\")\n",
    "plt.title(\"Fraction correct\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
