{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence_similarity_ops\n",
    "\n",
    "> Ops for computing quantities based on sequence similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sequence_similarity_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Stdlib imports\n",
    "from collections.abc import Sequence\n",
    "from typing import Optional, Union\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "def smooth_hamming_similarities_cdist(x: torch.Tensor, p: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"Smooth extension of the normalized Hamming similarity between all pairs of sequences in `x`.\n",
    "    `x` must have shape (..., N, L, R), and the result has shape (..., N, N).\"\"\"\n",
    "    length = x.shape[-2]\n",
    "    x = x.flatten(start_dim=-2)\n",
    "    norm_similarities = 1 - (torch.cdist(x, x, p=p) ** p) / (2 * length)\n",
    "\n",
    "    return norm_similarities\n",
    "\n",
    "\n",
    "def smooth_hamming_similarities_dot(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Smooth extension of the normalized Hamming similarity between all pairs of sequences in `x`.\n",
    "    `x` must have shape (..., N, L, R), and the result has shape (..., N, N).\"\"\"\n",
    "    length = x.shape[-2]\n",
    "    norm_similarities = torch.einsum(\"...mia,...nia->...mn\", x, x) / length\n",
    "\n",
    "    return norm_similarities\n",
    "\n",
    "\n",
    "def smooth_substitution_matrix_similarities(\n",
    "    x: torch.Tensor,\n",
    "    subs_mat: torch.Tensor,\n",
    "    use_scoredist: bool = False,\n",
    "    expected_value: Optional[float] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"TODO.\"\"\"\n",
    "    length = x.shape[-2]\n",
    "    scores = torch.einsum(\"...mia,ab,...nib->...mn\", x, subs_mat, x)\n",
    "    if use_scoredist:\n",
    "        # ScoreDist: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-6-108\n",
    "        expected_scores_null = expected_value * length\n",
    "        scores_norm = torch.clamp(scores - expected_scores_null, min=1e-8)\n",
    "        diagonal_scores = scores.diagonal(dim1=-2, dim2=-1)\n",
    "        score_upper_bounds = (\n",
    "            diagonal_scores.unsqueeze(-1) + diagonal_scores.unsqueeze(-2)\n",
    "        ) / 2\n",
    "        score_upper_bounds_norm = score_upper_bounds - expected_scores_null\n",
    "\n",
    "        return torch.log(scores_norm / score_upper_bounds_norm)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def _reciprocate_best_hits(best_hits: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Point-wise multiply best hits graphs with their transpose to obtain\n",
    "    reciprocal best hits graphs. `best_hits` must have shape (..., N, N).\"\"\"\n",
    "    return best_hits * best_hits.mT\n",
    "\n",
    "\n",
    "def soft_best_hits(\n",
    "    similarities: torch.Tensor,\n",
    "    *,\n",
    "    reciprocal: bool = False,\n",
    "    group_slices: Sequence[slice],\n",
    "    tau: Union[float, torch.Tensor] = 0.1,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Soft reciprocal best hits graphs from pairwise similarities.\n",
    "    `similarities` must have shape (..., N, N).\"\"\"\n",
    "    best_hits = torch.empty_like(similarities)\n",
    "    for sl in group_slices:\n",
    "        best_hits[..., sl].copy_(softmax(similarities[..., sl] / tau, dim=-1))\n",
    "\n",
    "    if reciprocal:\n",
    "        best_hits = _reciprocate_best_hits(best_hits)\n",
    "\n",
    "    return best_hits\n",
    "\n",
    "\n",
    "def hard_best_hits(\n",
    "    similarities: torch.Tensor,\n",
    "    *,\n",
    "    reciprocal: bool = False,\n",
    "    group_slices: Sequence[slice],\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Hard reciprocal best hits graphs from pairwise similarities.\n",
    "    `similarities` must have shape (..., N, N).\"\"\"\n",
    "    best_hits = torch.zeros_like(similarities, requires_grad=False)\n",
    "    for sl in group_slices:\n",
    "        argmax = torch.argmax(similarities[..., sl], dim=-1, keepdim=True)\n",
    "        best_hits[..., sl].scatter_(-1, argmax, 1.0)\n",
    "\n",
    "    if reciprocal:\n",
    "        best_hits = _reciprocate_best_hits(best_hits)\n",
    "\n",
    "    return best_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(soft_reciprocal_best_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(hard_reciprocal_best_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_soft_reciprocal_best_hits_bounds():\n",
    "    group_slices = [\n",
    "        slice(0, 4), slice(4, 7), slice(7, 10), slice(10, 18), slice(18, 20)\n",
    "    ]\n",
    "    x = torch.randn(20, 6)\n",
    "    similarities = torch.cdist(x, x, p=1)\n",
    "    similarities /= similarities.max()\n",
    "    srbh = soft_reciprocal_best_hits(similarities, group_slices=group_slices)\n",
    "\n",
    "    assert srbh.shape == similarities.shape\n",
    "    assert torch.all(torch.logical_and(srbh <= 1, srbh >= 0))\n",
    "\n",
    "\n",
    "test_soft_reciprocal_best_hits_bounds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
