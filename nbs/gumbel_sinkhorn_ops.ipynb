{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gumbel_sinkhorn_ops\n",
    "\n",
    "> Gumbel-Sinkhorn and Gumbel-matching operators\n",
    "> Modified from: [https://github.com/perrying/gumbel-sinkhorn](https://github.com/perrying/gumbel-sinkhorn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout, a permutation $0 \\to p_0, 1 \\to p_1, ..., n-1 \\to p_{n-1}$ is encoded by the permutation matrix $P = (p_{ij})_{i,j=0}^{n-1}$ with $p_{ij} = 1$ if and only if $j = p_i$, and $0$ otherwise.\n",
    "\n",
    "In NumPy/PyTorch, ``P[arange(n), p]`` is identically equal to ``1``, and we can obtain ``p`` from ``P`` by ``p = P.argmax(-1)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp gumbel_sinkhorn_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "\n",
    "\n",
    "def randperm_mat_like(log_alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Generate a random permutation matrix with the same shape as ``log_alpha[-2:]``.\n",
    "    Assume log_alpha is of shape (*batch_size, n, n).\"\"\"\n",
    "    size = log_alpha.size()[-2:]\n",
    "    n = size[0]\n",
    "    rp_mat = torch.zeros(\n",
    "        size, dtype=log_alpha.dtype, layout=log_alpha.layout, device=log_alpha.device\n",
    "    )\n",
    "    rp_mat[torch.arange(n), torch.randperm(n)] = 1\n",
    "\n",
    "    return rp_mat\n",
    "\n",
    "\n",
    "def unbias_by_randperms(func: callable) -> callable:\n",
    "    \"\"\"Decorator to unbias `func` with two random permutations.\"\"\"\n",
    "\n",
    "    def wrapper(log_alpha: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n",
    "        # Create two random permutation matrices\n",
    "        rand_perms = (randperm_mat_like(log_alpha), randperm_mat_like(log_alpha))\n",
    "        # Conjugate log_alpha with the two random permutation matrices\n",
    "        log_alpha_conj = rand_perms[0] @ log_alpha @ rand_perms[1].mT\n",
    "        # Apply the function\n",
    "        out_conj = func(log_alpha_conj, *args, **kwargs)\n",
    "        # Conjugate back\n",
    "        out_unconj = rand_perms[0].mT @ out_conj @ rand_perms[1]\n",
    "        return out_unconj\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def gumbel_noise_like(\n",
    "    log_alpha: torch.Tensor, noise_factor: float = 1.0, noise_std: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Generate rescaled Gumbel noise with the same shape as log_alpha.\n",
    "    The noise is rescaled by `noise_factor` or, if `noise_std` is True,\n",
    "    by `noise_factor` times the standard deviation of log_alpha.\"\"\"\n",
    "    uniform_noise = torch.rand_like(log_alpha)\n",
    "    gumbel_noise = -torch.log(-torch.log(uniform_noise + 1e-20) + 1e-20)\n",
    "    std = torch.std(log_alpha, dim=(-2, -1), keepdim=True)\n",
    "    if noise_std:\n",
    "        noise_factor = noise_factor * std\n",
    "\n",
    "    return noise_factor * gumbel_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sinkhorn_norm(alpha: torch.Tensor, n_iter: int = 20) -> torch.Tensor:\n",
    "    \"\"\"Iterative Sinkhorn normalization of non-negative matrices.\"\"\"\n",
    "    for _ in range(n_iter):\n",
    "        alpha = alpha / alpha.sum(-1, keepdim=True)\n",
    "        alpha = alpha / alpha.sum(-2, keepdim=True)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def log_sinkhorn_norm(log_alpha: torch.Tensor, n_iter: int = 20) -> torch.Tensor:\n",
    "    \"\"\"Iterative Sinkhorn normalization in log space, for numerical stability.\"\"\"\n",
    "    for _ in range(n_iter):\n",
    "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -1, keepdim=True)\n",
    "        log_alpha = log_alpha - torch.logsumexp(log_alpha, -2, keepdim=True)\n",
    "\n",
    "    return log_alpha\n",
    "\n",
    "\n",
    "def gumbel_sinkhorn(\n",
    "    log_alpha: torch.Tensor,\n",
    "    *,\n",
    "    tau: Union[float, torch.Tensor] = 1.0,\n",
    "    n_iter: int = 10,\n",
    "    noise: bool = False,\n",
    "    noise_factor: float = 1.0,\n",
    "    noise_std: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Gumbel-Sinkhorn operator with a temperature parameter `tau`.\n",
    "    Given arbitrary square matrices, outputs bistochastic matrices that are close to\n",
    "    permutation matrices when `tau` is small.\"\"\"\n",
    "    if noise:\n",
    "        log_alpha = log_alpha + gumbel_noise_like(\n",
    "            log_alpha, noise_factor=noise_factor, noise_std=noise_std\n",
    "        )\n",
    "    log_alpha = log_alpha / tau\n",
    "    bistochastic_mats = torch.exp(log_sinkhorn_norm(log_alpha, n_iter))\n",
    "\n",
    "    return bistochastic_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(gumbel_sinkhorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def np_matching(cost: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Find an assignment matrix with maximum cost, using the Hungarian algorithm.\n",
    "    Return the matrix in dense format.\"\"\"\n",
    "    row, col = linear_sum_assignment(cost, maximize=True)\n",
    "    np_matching_mat = np.zeros_like(cost)\n",
    "    np_matching_mat[row, col] = 1\n",
    "\n",
    "    return np_matching_mat\n",
    "\n",
    "\n",
    "def matching(\n",
    "    log_alpha: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    np_log_alpha = log_alpha.detach().clone().cpu().numpy()\n",
    "    np_matching_mats = np.zeros_like(np_log_alpha)\n",
    "    for idx in np.ndindex(np_log_alpha.shape[:-2]):\n",
    "        np_matching_mats[idx] = np_matching(np_log_alpha[idx])\n",
    "    matching_mats = (\n",
    "        torch.from_numpy(np_matching_mats).to(log_alpha.device).to(log_alpha.dtype)\n",
    "    )\n",
    "\n",
    "    return matching_mats\n",
    "\n",
    "\n",
    "def gumbel_matching(\n",
    "    log_alpha: torch.Tensor,\n",
    "    *,\n",
    "    noise: bool = False,\n",
    "    noise_factor: float = 1.0,\n",
    "    noise_std: bool = False,\n",
    "    unbias_lsa: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Gumbel-matching operator, i.e. the solution of the linear assignment problem with\n",
    "    optional Gumbel noise.\"\"\"\n",
    "    if noise:\n",
    "        log_alpha = log_alpha + gumbel_noise_like(\n",
    "            log_alpha, noise_factor=noise_factor, noise_std=noise_std\n",
    "        )\n",
    "    gumbel_matching_impl = unbias_by_randperms(matching) if unbias_lsa else matching\n",
    "    assignment_mat = gumbel_matching_impl(log_alpha)\n",
    "\n",
    "    return assignment_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(gumbel_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def inverse_permutation(x: torch.Tensor, mats: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"When mats contains permutation matrices, exchange the rows of `x` using the inverse(s)\n",
    "    of the permutation(s) encoded in `mats`.\"\"\"\n",
    "    return mats.mT @ x.to(mats.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
