{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e8f88-8bca-4db0-b710-a4bc7259437b",
   "metadata": {},
   "source": [
    "# data_utils\n",
    "\n",
    "> Utilities for dataset generation and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870ea3-a486-4d9b-960f-1fe61cbe59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398fe56d780fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694feb4b67b4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1ed29597a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections.abc import Sequence\n",
    "from typing import Optional, Union\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from diffpass.constants import DEFAULT_AA_TO_INT\n",
    "\n",
    "# Type aliases\n",
    "SeqRecord = tuple[str, str]\n",
    "SeqRecords = list[SeqRecord]\n",
    "GroupwiseSeqRecords = dict[str, SeqRecords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab247fe76e120ee",
   "metadata": {},
   "source": [
    "## Type aliases\n",
    "\n",
    "```python\n",
    "SeqRecord: tuple[str, str]\n",
    "SeqRecords: list[SeqRecord]\n",
    "GroupwiseSeqRecords: dict[str, SeqRecords]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93722153-82d9-4fa2-9800-d231a594c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_groupwise_seq_records(\n",
    "    seq_records: SeqRecords,\n",
    "    group_name_func: callable,\n",
    "    *,\n",
    "    remove_groups_with_one_seq: bool = True,\n",
    ") -> GroupwiseSeqRecords:\n",
    "    \"\"\"Group records of the form ``(header, sequence)`` in a collection by group name\n",
    "    (e.g. species name), extracted from header information using `group_name_func`.\"\"\"\n",
    "    data_group_by_group = defaultdict(SeqRecords)\n",
    "    for rec in seq_records:\n",
    "        group_name = group_name_func(rec[0])\n",
    "        data_group_by_group[group_name].append(rec)\n",
    "\n",
    "    if remove_groups_with_one_seq:\n",
    "        for group_name in list(data_group_by_group.keys()):\n",
    "            if len(data_group_by_group[group_name]) < 2:\n",
    "                data_group_by_group.pop(group_name)\n",
    "\n",
    "    return data_group_by_group\n",
    "\n",
    "\n",
    "def remove_groups_not_in_both(\n",
    "    data_group_by_group_x: GroupwiseSeqRecords,\n",
    "    data_group_by_group_y: GroupwiseSeqRecords,\n",
    ") -> tuple[GroupwiseSeqRecords, GroupwiseSeqRecords]:\n",
    "    \"\"\"Remove groups that are not present in both input collections.\"\"\"\n",
    "    group_names = set(data_group_by_group_x.keys()) & set(data_group_by_group_y.keys())\n",
    "\n",
    "    data_group_by_group_x_common = {\n",
    "        group_name: data_group_by_group_x[group_name] for group_name in group_names\n",
    "    }\n",
    "    data_group_by_group_y_common = {\n",
    "        group_name: data_group_by_group_y[group_name] for group_name in group_names\n",
    "    }\n",
    "\n",
    "    return data_group_by_group_x_common, data_group_by_group_y_common\n",
    "\n",
    "\n",
    "def pad_msas_with_dummy_sequences(\n",
    "    data_group_by_group_x: GroupwiseSeqRecords,\n",
    "    data_group_by_group_y: GroupwiseSeqRecords,\n",
    "    *,\n",
    "    dummy_symbol: str = \"-\",\n",
    ") -> tuple[GroupwiseSeqRecords, GroupwiseSeqRecords]:\n",
    "    \"\"\"Pad MSAs with dummy sequences so that all groups/species contain the same\n",
    "    number of sequences.\"\"\"\n",
    "    # Check that all sequences in the x and y MSAs have the same length\n",
    "    lengths_x = set(\n",
    "        [\n",
    "            len(seq)\n",
    "            for data_x_this_group in data_group_by_group_x.values()\n",
    "            for _, seq in data_x_this_group\n",
    "        ]\n",
    "    )\n",
    "    lengths_y = set(\n",
    "        [\n",
    "            len(seq)\n",
    "            for data_y_this_group in data_group_by_group_y.values()\n",
    "            for _, seq in data_y_this_group\n",
    "        ]\n",
    "    )\n",
    "    if len(lengths_x) != 1:\n",
    "        raise ValueError(\n",
    "            \"Sequences in the first input collection must have the same lengths for padding with dummy gap sequences.\"\n",
    "        )\n",
    "    if len(lengths_y) != 1:\n",
    "        raise ValueError(\n",
    "            \"Sequences in the second input collection must have the same lengths for padding with dummy gap sequences.\"\n",
    "        )\n",
    "    len_x = next(iter(lengths_x))\n",
    "    len_y = next(iter(lengths_y))\n",
    "\n",
    "    group_names = set(data_group_by_group_x.keys()) | set(data_group_by_group_y.keys())\n",
    "\n",
    "    data_group_by_group_x_padded = defaultdict(SeqRecords)\n",
    "    data_group_by_group_y_padded = defaultdict(SeqRecords)\n",
    "    data_group_by_group_x_padded.update(deepcopy(data_group_by_group_x))\n",
    "    data_group_by_group_y_padded.update(deepcopy(data_group_by_group_y))\n",
    "    for group_name in group_names:\n",
    "        max_depth = max(\n",
    "            len(data_group_by_group_x[group_name]),\n",
    "            len(data_group_by_group_y[group_name]),\n",
    "        )\n",
    "        data_group_by_group_x_padded[group_name] += [\n",
    "            (f\"dummy_{i}\", dummy_symbol * len_x)\n",
    "            for i in range(max_depth - len(data_group_by_group_x[group_name]))\n",
    "        ]\n",
    "        data_group_by_group_y_padded[group_name] += [\n",
    "            (f\"dummy_{i}\", dummy_symbol * len_y)\n",
    "            for i in range(max_depth - len(data_group_by_group_y[group_name]))\n",
    "        ]\n",
    "\n",
    "    return data_group_by_group_x_padded, data_group_by_group_y_padded\n",
    "\n",
    "\n",
    "def get_single_and_paired_seqs(\n",
    "    data_group_by_group_x: GroupwiseSeqRecords,\n",
    "    data_group_by_group_y: GroupwiseSeqRecords,\n",
    "    *,\n",
    "    group_names: Optional[Sequence[str]] = None,\n",
    ") -> dict[str, Union[list[list[tuple]], list[dict[str, int]]]]:\n",
    "    \"\"\"Single and paired sequences from two sequence records. The paired sequences are returned as a list of\n",
    "    dictionaries, where the keys are the concatenated sequences and the values are the number of\n",
    "    times that pair appears in the concatenated MSA.\"\"\"\n",
    "    if group_names is None:\n",
    "        group_names = set(data_group_by_group_x.keys()) | set(\n",
    "            data_group_by_group_y.keys()\n",
    "        )\n",
    "\n",
    "    x_seqs_by_group = {}\n",
    "    y_seqs_by_group = {}\n",
    "    xy_seqs_to_counts_by_group = {}\n",
    "    for group_name in group_names:\n",
    "        x_seqs_this_group = list(zip(*data_group_by_group_x[group_name]))[1]\n",
    "        y_seqs_this_group = list(zip(*data_group_by_group_y[group_name]))[1]\n",
    "        x_seqs_by_group[group_name] = x_seqs_this_group\n",
    "        y_seqs_by_group[group_name] = y_seqs_this_group\n",
    "        xy_seqs_to_counts_by_group[group_name] = {}\n",
    "        xy_seqs_this_group = [\n",
    "            f\"{x_seq}:{y_seq}\"\n",
    "            for x_seq, y_seq in zip(x_seqs_this_group, y_seqs_this_group)\n",
    "        ]\n",
    "        if xy_seqs_this_group:\n",
    "            unique_xy_this_group, counts_xy_this_group = np.unique(\n",
    "                np.array(xy_seqs_this_group), return_counts=True\n",
    "            )\n",
    "            xy_seqs_to_counts_by_group[group_name].update(\n",
    "                dict(zip(unique_xy_this_group, counts_xy_this_group))\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"x_seqs_by_group\": x_seqs_by_group,\n",
    "        \"y_seqs_by_group\": y_seqs_by_group,\n",
    "        \"xy_seqs_to_counts_by_group\": xy_seqs_to_counts_by_group,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3537003c07ccc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### create_groupwise_seq_records\n\n>      create_groupwise_seq_records (seq_records:list[tuple[str,str]],\n>                                    group_name_func:<built-infunctioncallable>,\n>                                    remove_groups_with_one_seq:bool=True)\n\n*Group records of the form ``(header, sequence)`` in a collection by group name\n(e.g. species name), extracted from header information using `group_name_func`.*",
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### create_groupwise_seq_records\n",
       "\n",
       ">      create_groupwise_seq_records (seq_records:list[tuple[str,str]],\n",
       ">                                    group_name_func:<built-infunctioncallable>,\n",
       ">                                    remove_groups_with_one_seq:bool=True)\n",
       "\n",
       "*Group records of the form ``(header, sequence)`` in a collection by group name\n",
       "(e.g. species name), extracted from header information using `group_name_func`.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(create_groupwise_seq_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27afc8aa6bbe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n### remove_groups_not_in_both\n\n>      remove_groups_not_in_both\n>                                 (data_group_by_group_x:dict[str,list[tuple[str\n>                                 ,str]]], data_group_by_group_y:dict[str,list[t\n>                                 uple[str,str]]])\n\n*Remove groups that are not present in both input collections.*",
      "text/plain": [
       "---\n",
       "\n",
       "### remove_groups_not_in_both\n",
       "\n",
       ">      remove_groups_not_in_both\n",
       ">                                 (data_group_by_group_x:dict[str,list[tuple[str\n",
       ">                                 ,str]]], data_group_by_group_y:dict[str,list[t\n",
       ">                                 uple[str,str]]])\n",
       "\n",
       "*Remove groups that are not present in both input collections.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(remove_groups_not_in_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115413bf4ce41d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### pad_msas_with_dummy_sequences\n\n>      pad_msas_with_dummy_sequences\n>                                     (data_group_by_group_x:dict[str,list[tuple\n>                                     [str,str]]], data_group_by_group_y:dict[st\n>                                     r,list[tuple[str,str]]],\n>                                     dummy_symbol:str='-')\n\n*Pad MSAs with dummy sequences so that all groups/species contain the same\nnumber of sequences.*",
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### pad_msas_with_dummy_sequences\n",
       "\n",
       ">      pad_msas_with_dummy_sequences\n",
       ">                                     (data_group_by_group_x:dict[str,list[tuple\n",
       ">                                     [str,str]]], data_group_by_group_y:dict[st\n",
       ">                                     r,list[tuple[str,str]]],\n",
       ">                                     dummy_symbol:str='-')\n",
       "\n",
       "*Pad MSAs with dummy sequences so that all groups/species contain the same\n",
       "number of sequences.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(pad_msas_with_dummy_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17262f0056419d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def one_hot_encode_msa(\n",
    "    seq_records: SeqRecords,\n",
    "    aa_to_int: Optional[dict[str, int]] = None,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given a list of records of the form (header, sequence), assumed to be a parsed MSA,\n",
    "    tokenize each sequence and one-hot encode each token. Return a 3D tensor representing the\n",
    "    one-hot encoded MSA.\n",
    "    \"\"\"\n",
    "    if aa_to_int is None:\n",
    "        aa_to_int = DEFAULT_AA_TO_INT\n",
    "\n",
    "    tokenized_records = []\n",
    "    for header, seq in seq_records:\n",
    "        tokenized_records.append([aa_to_int[c] for c in seq])\n",
    "    tokenized_records = torch.tensor(tokenized_records, device=device)\n",
    "\n",
    "    tokenized_records_oh = torch.nn.functional.one_hot(tokenized_records).to(\n",
    "        torch.get_default_dtype()\n",
    "    )\n",
    "\n",
    "    return tokenized_records_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f678350cb9cd553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L100){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### one_hot_encode_msa\n\n>      one_hot_encode_msa (seq_records:list[tuple[str,str]],\n>                          aa_to_int:Optional[dict[str,int]]=None,\n>                          device:Optional[torch.device]=None)\n\nGiven a list of records of the form (header, sequence), assumed to be a parsed MSA,\ntokenize each sequence and one-hot encode each token. Return a 3D tensor representing the\none-hot encoded MSA.",
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L100){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### one_hot_encode_msa\n",
       "\n",
       ">      one_hot_encode_msa (seq_records:list[tuple[str,str]],\n",
       ">                          aa_to_int:Optional[dict[str,int]]=None,\n",
       ">                          device:Optional[torch.device]=None)\n",
       "\n",
       "Given a list of records of the form (header, sequence), assumed to be a parsed MSA,\n",
       "tokenize each sequence and one-hot encode each token. Return a 3D tensor representing the\n",
       "one-hot encoded MSA."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(one_hot_encode_msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914189a5ff5fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_num_correct_pairings(\n",
    "    hard_perms_by_group: list[np.ndarray],\n",
    "    *,\n",
    "    compare_to_identity_permutation: bool,\n",
    "    single_and_paired_seqs: Optional[dict[str, list]] = None,\n",
    ") -> int:\n",
    "    \"\"\"Compute the total number of correct pairings.\n",
    "    'Correct' means that they are present in the original paired MSAs, assumed to be the\n",
    "    ground truth.\n",
    "\n",
    "    If `compare_to_identity_permutation` is True, then the correct pairings are assumed\n",
    "    to be given by the identity permutation, and the `x_seqs`, `y_seqs`, and `xy_seqs`\n",
    "    arguments are ignored.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    if compare_to_identity_permutation:\n",
    "        for perm_this_group in hard_perms_by_group:\n",
    "            n_seqs_this_group = perm_this_group.shape[-1]\n",
    "            correct_this_group = np.sum(perm_this_group == np.arange(n_seqs_this_group))\n",
    "            correct += correct_this_group\n",
    "    else:\n",
    "        x_seqs_by_group = single_and_paired_seqs[\"x_seqs_by_group\"]\n",
    "        y_seqs_by_group = single_and_paired_seqs[\"y_seqs_by_group\"]\n",
    "        xy_seqs_to_counts_by_group = single_and_paired_seqs[\n",
    "            \"xy_seqs_to_counts_by_group\"\n",
    "        ]\n",
    "        for (\n",
    "            perm_this_group,\n",
    "            x_seqs_this_group,\n",
    "            y_seqs_this_group,\n",
    "            xy_seqs_to_counts_this_group,\n",
    "        ) in zip(\n",
    "            hard_perms_by_group,\n",
    "            x_seqs_by_group,\n",
    "            y_seqs_by_group,\n",
    "            xy_seqs_to_counts_by_group,\n",
    "        ):\n",
    "            _xy_seqs_to_counts_this_group = xy_seqs_to_counts_this_group.copy()\n",
    "            x_seqs_this_group_perm = [x_seqs_this_group[idx] for idx in perm_this_group]\n",
    "            for x_seq, y_seq in zip(x_seqs_this_group_perm, y_seqs_this_group):\n",
    "                xy_key = f\"{x_seq}:{y_seq}\"\n",
    "                if _xy_seqs_to_counts_this_group.get(xy_key, 0) > 0:\n",
    "                    _xy_seqs_to_counts_this_group[xy_key] -= 1\n",
    "                    correct += 1\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc31a2721c0817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### compute_num_correct_pairings\n\n>      compute_num_correct_pairings (hard_perms_by_group:list[numpy.ndarray],\n>                                    compare_to_identity_permutation:bool, singl\n>                                    e_and_paired_seqs:Optional[dict[str,list]]=\n>                                    None)\n\nCompute the total number of correct pairings.\n'Correct' means that they are present in the original paired MSAs, assumed to be the\nground truth.\n\nIf `compare_to_identity_permutation` is True, then the correct pairings are assumed\nto be given by the identity permutation, and the `x_seqs`, `y_seqs`, and `xy_seqs`\narguments are ignored.",
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Bitbol-Lab/DiffPaSS/blob/main/diffpass/data_utils.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compute_num_correct_pairings\n",
       "\n",
       ">      compute_num_correct_pairings (hard_perms_by_group:list[numpy.ndarray],\n",
       ">                                    compare_to_identity_permutation:bool, singl\n",
       ">                                    e_and_paired_seqs:Optional[dict[str,list]]=\n",
       ">                                    None)\n",
       "\n",
       "Compute the total number of correct pairings.\n",
       "'Correct' means that they are present in the original paired MSAs, assumed to be the\n",
       "ground truth.\n",
       "\n",
       "If `compare_to_identity_permutation` is True, then the correct pairings are assumed\n",
       "to be given by the identity permutation, and the `x_seqs`, `y_seqs`, and `xy_seqs`\n",
       "arguments are ignored."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(compute_num_correct_pairings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c51647ce6bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_comparable_group_idxs(\n",
    "    group_sizes_arr: np.ndarray, *, max_size_ratio: int, max_group_size: int\n",
    ") -> np.ndarray:\n",
    "    # 1) Groups which have non-zero count for both families but where not both counts are equal to 1\n",
    "    # NOTE: In AlphaFold this excludes the query (dummy group of size 1)\n",
    "    mask_not_zero_in_one = (group_sizes_arr[:, 0] * group_sizes_arr[:, 1] != 0) * (\n",
    "        group_sizes_arr[:, 0] * group_sizes_arr[:, 1] != 1\n",
    "    )\n",
    "\n",
    "    # 2) Groups which have non-zero count for both families and where not both counts are equal to 1 and where group size are not too different\n",
    "    mask_comparable = (\n",
    "        np.divide(\n",
    "            np.max(group_sizes_arr, axis=1), np.min(group_sizes_arr, axis=1) + 1e-50\n",
    "        )\n",
    "        <= max_size_ratio\n",
    "    )\n",
    "    mask_comparable *= mask_not_zero_in_one\n",
    "\n",
    "    # 3) Remove groups that are too large\n",
    "    mask_max_group_size = np.max(group_sizes_arr, axis=1) <= max_group_size\n",
    "\n",
    "    idx_comparable = np.flatnonzero(\n",
    "        np.logical_and(mask_comparable, mask_max_group_size)\n",
    "    )\n",
    "\n",
    "    msa_depth = np.max(group_sizes_arr[idx_comparable], axis=1).sum()\n",
    "    print(f\"Final MSA_depth = {msa_depth}\")\n",
    "\n",
    "    print(f\"Number of comparable groups = {len(idx_comparable)}\")\n",
    "\n",
    "    return idx_comparable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
