{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiffPASS â€“ Example usage on prokaryotic datasets\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# DiffPASS imports\n",
    "from diffpass.train import InformationAndReciprocalBestHits\n",
    "from diffpass.msa_parsing import read_msa\n",
    "from diffpass.data_utils import generate_dataset, dataset_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one of the two prokaryotic datasets: HK-RR and MALG-MALK.\n",
    "\n",
    "`get_species_name` extracts species names from the FASTA header.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROKARYOTIC DATASETS\n",
    "\n",
    "msa_data = [\n",
    "    read_msa(\"data/HK-RR/HK_in_Concat_nnn.fasta\", -1),\n",
    "    read_msa(\"data/HK-RR/RR_in_Concat_nnn.fasta\", -1)\n",
    "]\n",
    "get_species_name = lambda header: header.split(\"|\")[1]\n",
    "\n",
    "# msa_data = [\n",
    "#     read_msa(\"data/MALG-MALK/MALG_cov75_hmmsearch_extr5000_withLast_b.fasta\", -1),\n",
    "#     read_msa(\"data/MALG-MALK/MALK_cov75_hmmsearch_extr5000_withLast_b.fasta\", -1)\n",
    "# ]\n",
    "# get_species_name = lambda header: header.split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dataset = {\n",
    "    \"N\": 500,  # Average number of sequences in the input\n",
    "    \"pos\": 0,  # Size of the context pairs to use as positive example \n",
    "    \"max_size\": 100,  # Max size of species MSAs (if same as N there is no limit on size)\n",
    "    \"NUMPY_SEED\": 10,\n",
    "    \"NUMPY_SEED_OTHER\": 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, group_sizes = generate_dataset(\n",
    "    parameters_dataset, msa_data, get_species_name=get_species_name\n",
    ")\n",
    "tokenized_dataset = dataset_tokenizer(dataset)\n",
    "\n",
    "x, y = tokenized_dataset[\"msa\"][\"left\"], tokenized_dataset[\"msa\"][\"right\"]\n",
    "positive_examples = tokenized_dataset[\"positive_examples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to shuffle the sequences within each species. This can be a useful control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_species_random_shuffle(\n",
    "    x: torch.Tensor,\n",
    "    *,\n",
    "    group_sizes: np.ndarray\n",
    "):\n",
    "    idx = 0\n",
    "    for s in group_sizes:\n",
    "        x[idx:s + idx, ...] = x[idx:s + idx][torch.randperm(s)]\n",
    "        idx += s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairings using DiffPASS's `InformationAndReciprocalBestHits` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SEED = 100\n",
    "torch.manual_seed(TORCH_SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for soft permutations (Gumbel-Sinkhorn)\n",
    "permutation_cfg = {\n",
    "    \"tau\": torch.tensor(1e-2),\n",
    "    \"n_iter\": 10,\n",
    "    \"noise\": False,\n",
    "}\n",
    "\n",
    "# Information-theoretic part of the loss: whether we use two-body entropy or mutual information\n",
    "information_measure = \"TwoBodyEntropy\"\n",
    "\n",
    "# Settings affecting the reciprocal best hits part of the loss\n",
    "hamming_similarities_cfg = {\n",
    "    \"use_dot\": False,\n",
    "    \"p\": 1\n",
    "}\n",
    "reciprocal_best_hits_cfg = {\n",
    "    \"tau\": torch.tensor(1e-1)\n",
    "}\n",
    "inter_group_loss_score_fn = torch.dot  #torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "# Loss weights\n",
    "loss_weights = {\n",
    "    information_measure: 1.,\n",
    "    \"ReciprocalBestHits\": 1.,\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = torch.device(\n",
    "    f\"cuda{(':' + input('Enter the CUDA device number:')) if torch.cuda.device_count() > 1 else ''}\"\n",
    "    if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpass = InformationAndReciprocalBestHits(\n",
    "    group_sizes=group_sizes,\n",
    "    fixed_matchings=None,\n",
    "    loss_weights=loss_weights,\n",
    "    permutation_cfg=permutation_cfg,\n",
    "    information_measure=information_measure,\n",
    "    hamming_similarities_cfg=hamming_similarities_cfg,\n",
    "    reciprocal_best_hits_cfg=reciprocal_best_hits_cfg,\n",
    "    inter_group_loss_score_fn=inter_group_loss_score_fn,\n",
    ")\n",
    "\n",
    "dpass.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "fit_cfg = {\n",
    "    \"epochs\": 400,\n",
    "    \"optimizer_name\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\"lr\": 1e-1, \"weight_decay\": 0.},\n",
    "    \"mean_centering\": True,\n",
    "    \"hamming_gradient_bypass\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dpass.fit(\n",
    "    x,\n",
    "    y,\n",
    "    **fit_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_losses_total = 0\n",
    "soft_losses_total = 0\n",
    "hard_loss_id_total = 0\n",
    "soft_loss_id_total = 0\n",
    "for loss_kind in results.hard_losses:\n",
    "    hard_losses = np.array([x.item() for x in results.hard_losses[loss_kind]])\n",
    "    soft_losses = np.array([x.item() for x in results.soft_losses[loss_kind]])\n",
    "    hard_losses_total += hard_losses\n",
    "    soft_losses_total += soft_losses\n",
    "    correct = [\n",
    "        sum([\n",
    "            (perm == torch.arange(\n",
    "                perm.shape[-1]\n",
    "            )).sum().item() for perm in perms\n",
    "        ])\n",
    "        for perms in results.hard_perms\n",
    "    ]\n",
    "    hard_loss_id = results.hard_losses_identity_perm[loss_kind]\n",
    "    soft_loss_id = results.soft_losses_identity_perm[loss_kind]\n",
    "    hard_loss_id_total += hard_loss_id\n",
    "    soft_loss_id_total += soft_loss_id\n",
    "\n",
    "    plt.plot(hard_losses)\n",
    "    plt.axhline(hard_loss_id)\n",
    "    ax_correct = plt.twinx()\n",
    "    ax_correct.plot(correct)\n",
    "    plt.title(f\"{loss_kind}, hard\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(soft_losses)\n",
    "    plt.axhline(soft_loss_id)\n",
    "    plt.title(f\"{loss_kind}, soft\")\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(hard_losses_total)\n",
    "plt.axhline(hard_loss_id_total)\n",
    "plt.title(\"Total, hard\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(soft_losses_total)\n",
    "plt.axhline(soft_loss_id_total)\n",
    "plt.title(\"Total, soft\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
