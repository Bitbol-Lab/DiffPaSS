{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "\n",
    "> Perform optimization using DiffPASS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Stdlib imports\n",
    "from collections.abc import Iterable, Sequence\n",
    "from typing import Optional, Union, Any, Literal\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "# DiffPASS imports\n",
    "from diffpass.base import EnsembleMixin, DiffPASSMixin, scalar_or_1d_tensor\n",
    "from diffpass.model import (\n",
    "    GeneralizedPermutation,\n",
    "    EnsembleMatrixApply,\n",
    "    TwoBodyEntropyLoss,\n",
    "    MILoss,\n",
    "    HammingSimilarities,\n",
    "    BestHits,\n",
    "    Blosum62Similarities,\n",
    "    InterGroupLoss,\n",
    "    IntraGroupLoss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def global_argmax_from_group_argmaxes(mats: Iterable[torch.Tensor]) -> torch.Tensor:\n",
    "    global_argmax = []\n",
    "    start_idx = 0\n",
    "    for mats_this_group in mats:\n",
    "        global_argmax.append(mats_this_group.argmax(-1) + start_idx)\n",
    "        start_idx += mats_this_group.shape[-1]\n",
    "\n",
    "    return torch.cat(global_argmax, dim=-1)\n",
    "\n",
    "\n",
    "def apply_hard_permutation_batch_to_similarity(\n",
    "    *, x: torch.Tensor, perms: list[torch.Tensor]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Conjugate a single similarity matrix by a batch of hard permutations.\n",
    "\n",
    "    Args:\n",
    "        perms: List of batches of permutation matrices of shape (..., D, D).\n",
    "        x: Similarity matrix of shape (D, D).\n",
    "\n",
    "    Returns:\n",
    "        Batch of conjugated matrices of shape (..., D, D).\n",
    "    \"\"\"\n",
    "    global_argmax = global_argmax_from_group_argmaxes(perms)\n",
    "    x_permuted_rows = x[global_argmax]\n",
    "\n",
    "    # Permuting columns is more involved\n",
    "    index = global_argmax.view(*global_argmax.shape[:-1], 1, -1).expand(\n",
    "        *global_argmax.shape, global_argmax.shape[-1]\n",
    "    )\n",
    "    # Example of gather with 4D tensor and dim=-1:\n",
    "    # out[i][j][k][l] = input[i][j][k][index[i][j][k][l]]\n",
    "\n",
    "    return torch.gather(x_permuted_rows, -1, index)\n",
    "\n",
    "\n",
    "def _dcc(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x.detach().clone().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_perm(shape: tuple[int, int, int, int]):\n",
    "    perms = torch.randn(*shape)\n",
    "    x = torch.randn(shape[-2], shape[-1])\n",
    "\n",
    "    argmax = perms.argmax(-1)\n",
    "    x_permuted_rows = x[argmax]\n",
    "    index = argmax.view(*argmax.shape[:-1], 1, -1).expand_as(perms)\n",
    "    output = torch.gather(x_permuted_rows, -1, index)\n",
    "\n",
    "    expected = torch.stack([\n",
    "        torch.stack([\n",
    "            x[argmax[i, j], :][:, argmax[i, j]] for j in range(shape[1])\n",
    "        ], dim=0) for i in range(shape[0])\n",
    "    ], dim=0)\n",
    "\n",
    "    assert torch.equal(output, expected)\n",
    "\n",
    "\n",
    "test_batch_perm((2, 5, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass\n",
    "class DiffPASSResults:\n",
    "    log_alphas: list[list[torch.Tensor]]\n",
    "    # Perms\n",
    "    soft_perms: list[list[torch.Tensor]]\n",
    "    hard_perms: list[list[torch.Tensor]]\n",
    "    # Losses\n",
    "    hard_losses: dict[str, list[torch.Tensor]]\n",
    "    soft_losses: dict[str, list[torch.Tensor]]\n",
    "    # Losses with identity perm\n",
    "    hard_losses_identity_perm: dict[str, Optional[float]]\n",
    "    soft_losses_identity_perm: Optional[dict[str, Optional[float]]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Information(Module, EnsembleMixin, DiffPASSMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        group_sizes: Iterable[int],\n",
    "        fixed_matchings: Optional[Sequence[Sequence[Sequence[int]]]] = None,\n",
    "        permutation_cfg: Optional[dict[str, Any]] = None,\n",
    "        information_measure: Literal[\"MI\", \"TwoBodyEntropy\"] = \"TwoBodyEntropy\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.group_sizes = tuple(s for s in group_sizes)\n",
    "        self.fixed_matchings = fixed_matchings\n",
    "        self.permutation_cfg = permutation_cfg\n",
    "        self.information_measure = information_measure\n",
    "\n",
    "        ensemble_shape = []\n",
    "        _dim_in_ensemble = -1\n",
    "\n",
    "        if permutation_cfg is None:\n",
    "            permutation_cfg = {}\n",
    "        else:\n",
    "            self.validate_permutation_cfg(permutation_cfg)\n",
    "            permutation_cfg = deepcopy(permutation_cfg)\n",
    "            _dim_in_ensemble = self._adjust_cfg_and_ensemble_shape(\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                cfg=permutation_cfg,\n",
    "                param_name=\"tau\",\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        self.effective_permutation_cfg_ = permutation_cfg\n",
    "        ensemble_shape = tuple(ensemble_shape)\n",
    "\n",
    "        self.validate_information_measure(information_measure)\n",
    "\n",
    "        self.permutation = GeneralizedPermutation(\n",
    "            group_sizes=self.group_sizes,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            fixed_matchings=fixed_matchings,\n",
    "            mode=\"soft\",\n",
    "            **permutation_cfg,\n",
    "        )\n",
    "        self.ensemble_matrix_apply = EnsembleMatrixApply(group_sizes=self.group_sizes)\n",
    "        if self.information_measure == \"TwoBodyEntropy\":\n",
    "            self.information_loss = TwoBodyEntropyLoss()\n",
    "        elif self.information_measure == \"MI\":\n",
    "            self.information_loss = MILoss()\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_cfg_and_ensemble_shape(\n",
    "        *,\n",
    "        ensemble_shape: list[int],\n",
    "        cfg: dict[str, Any],\n",
    "        param_name: str,\n",
    "        prev_dim_in_ensemble: int = -1,\n",
    "    ) -> int:\n",
    "        new_dim_in_ensemble = prev_dim_in_ensemble\n",
    "        if param_name in cfg:\n",
    "            param = scalar_or_1d_tensor(param=cfg[param_name], param_name=param_name)\n",
    "            cfg[param_name] = param\n",
    "            if param.ndim == 1:\n",
    "                ensemble_shape += list(param.shape)\n",
    "                new_dim_in_ensemble += 1\n",
    "                cfg[f\"{param_name}_dim_in_ensemble\"] = new_dim_in_ensemble\n",
    "\n",
    "        return new_dim_in_ensemble\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        mode = self.permutation.mode\n",
    "\n",
    "        # Soft or hard permutations (list)\n",
    "        perms = self.permutation()\n",
    "        x_perm = self.ensemble_matrix_apply(x, mats=perms)\n",
    "\n",
    "        # Two-body entropy portion of the loss\n",
    "        loss_info = self.information_loss(x_perm, y)\n",
    "\n",
    "        return {\"perms\": perms, \"x_perm\": x_perm, \"loss_info\": loss_info}\n",
    "\n",
    "    def soft_(self) -> None:\n",
    "        self.permutation.soft_()\n",
    "\n",
    "    def hard_(self) -> None:\n",
    "        self.permutation.hard_()\n",
    "\n",
    "    def _prepare_fit(self, x: torch.Tensor, y: torch.Tensor) -> DiffPASSResults:\n",
    "        # Validate inputs\n",
    "        self.validate_inputs(x, y)\n",
    "\n",
    "        # Initialize DiffPassResults object\n",
    "        results = DiffPASSResults(\n",
    "            log_alphas=[],\n",
    "            soft_perms=[],\n",
    "            hard_perms=[],\n",
    "            soft_losses={self.information_measure: []},\n",
    "            hard_losses={self.information_measure: []},\n",
    "            hard_losses_identity_perm={\n",
    "                self.information_measure: None,\n",
    "            },\n",
    "            soft_losses_identity_perm={\n",
    "                self.information_measure: None,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Compute hard losses with identity permutation\n",
    "        self.hard_()\n",
    "        with torch.no_grad():\n",
    "            results.hard_losses_identity_perm[\n",
    "                self.information_measure\n",
    "            ] = self.information_loss(x, y).item()\n",
    "            results.soft_losses_identity_perm[\n",
    "                self.information_measure\n",
    "            ] = results.hard_losses_identity_perm[self.information_measure]\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        results: DiffPASSResults,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        # Initialize optimizer\n",
    "        optimizer_cls = getattr(torch.optim, optimizer_name)\n",
    "        optimizer_kwargs = (\n",
    "            {\"lr\": 1e-1} if optimizer_kwargs is None else deepcopy(optimizer_kwargs)\n",
    "        )\n",
    "        self.optimizer_ = optimizer_cls(self.parameters(), **optimizer_kwargs)\n",
    "\n",
    "        # Progress bar\n",
    "        pbar = range(epochs + 1)\n",
    "        if show_pbar:\n",
    "            pbar = tqdm(pbar)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        ## Gradient descent\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        with torch.set_grad_enabled(True):\n",
    "            self.optimizer_.zero_grad()\n",
    "            for i in pbar:\n",
    "                # Hard pass\n",
    "                self.hard_()\n",
    "                with torch.no_grad():\n",
    "                    epoch_results = self(x, y)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.log_alphas.append(\n",
    "                        [_dcc(log_alpha) for log_alpha in self.permutation.log_alphas]\n",
    "                    )\n",
    "                    results.hard_perms.append(\n",
    "                        [\n",
    "                            _dcc(perms_this_group).argmax(-1).to(torch.int16)\n",
    "                            for perms_this_group in perms\n",
    "                        ]\n",
    "                    )\n",
    "                    results.hard_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "\n",
    "                # Soft pass\n",
    "                if i < epochs or compute_final_soft:\n",
    "                    self.soft_()\n",
    "                    epoch_results = self(x, y)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.soft_perms.append(\n",
    "                        [_dcc(perms_this_group) for perms_this_group in perms]\n",
    "                    )\n",
    "                    results.soft_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "\n",
    "                    loss = loss_info.sum()\n",
    "                    loss.backward()\n",
    "                if i < epochs:\n",
    "                    self.optimizer_.step()\n",
    "                    self.optimizer_.zero_grad()\n",
    "                    if mean_centering:\n",
    "                        with torch.no_grad():\n",
    "                            for log_alpha in self.permutation.log_alphas:\n",
    "                                log_alpha[...] -= log_alpha.mean(\n",
    "                                    dim=(-1, -2), keepdim=True\n",
    "                                )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        results = self._prepare_fit(x, y)\n",
    "        results = self._fit(\n",
    "            x,\n",
    "            y,\n",
    "            results,\n",
    "            epochs=epochs,\n",
    "            optimizer_name=optimizer_name,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            mean_centering=mean_centering,\n",
    "            show_pbar=show_pbar,\n",
    "            compute_final_soft=compute_final_soft,\n",
    "        )\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class InformationAndBestHits(Module, EnsembleMixin, DiffPASSMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        group_sizes: Iterable[int],\n",
    "        fixed_matchings: Optional[Sequence[Sequence[Sequence[int]]]] = None,\n",
    "        loss_weights: Optional[dict[str, Union[float, torch.Tensor]]] = None,\n",
    "        permutation_cfg: Optional[dict[str, Any]] = None,\n",
    "        information_measure: Literal[\"MI\", \"TwoBodyEntropy\"] = \"TwoBodyEntropy\",\n",
    "        similarity_kind: Literal[\"Hamming\", \"Blosum62\"] = \"Hamming\",\n",
    "        similarities_cfg: Optional[dict[str, Any]] = None,\n",
    "        best_hits_cfg: Optional[dict[str, Any]] = None,\n",
    "        inter_group_loss_score_fn: Optional[callable] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.group_sizes = tuple(s for s in group_sizes)\n",
    "        self.fixed_matchings = fixed_matchings\n",
    "        self.loss_weights = loss_weights\n",
    "        self.permutation_cfg = permutation_cfg\n",
    "        self.information_measure = information_measure\n",
    "        self.similarity_kind = similarity_kind\n",
    "        self.similarities_cfg = similarities_cfg\n",
    "        self.best_hits_cfg = best_hits_cfg\n",
    "        self.inter_group_loss_score_fn = inter_group_loss_score_fn\n",
    "\n",
    "        ensemble_shape = []\n",
    "        _dim_in_ensemble = -1\n",
    "\n",
    "        if permutation_cfg is None:\n",
    "            permutation_cfg = {}\n",
    "        else:\n",
    "            self.validate_permutation_cfg(permutation_cfg)\n",
    "            permutation_cfg = deepcopy(permutation_cfg)\n",
    "            _dim_in_ensemble = self._adjust_cfg_and_ensemble_shape(\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                cfg=permutation_cfg,\n",
    "                param_name=\"tau\",\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        self.effective_permutation_cfg_ = permutation_cfg\n",
    "\n",
    "        self.validate_information_measure(information_measure)\n",
    "        self.loss_weights_keys = {self.information_measure, \"BestHits\"}\n",
    "\n",
    "        self.validate_similarity_kind(similarity_kind)\n",
    "        if similarities_cfg is None:\n",
    "            similarities_cfg = {}\n",
    "        else:\n",
    "            self.validate_similarities_cfg(similarities_cfg)\n",
    "            similarities_cfg = deepcopy(similarities_cfg)\n",
    "        self.effective_similarities_cfg_ = similarities_cfg\n",
    "\n",
    "        if best_hits_cfg is None:\n",
    "            best_hits_cfg = {}\n",
    "        else:\n",
    "            self.validate_best_hits_cfg(best_hits_cfg)\n",
    "            best_hits_cfg = deepcopy(best_hits_cfg)\n",
    "            _dim_in_ensemble = self._adjust_cfg_and_ensemble_shape(\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                cfg=best_hits_cfg,\n",
    "                param_name=\"tau\",\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        self.effective_best_hits_cfg_ = best_hits_cfg\n",
    "\n",
    "        if loss_weights is not None:\n",
    "            loss_weights = deepcopy(loss_weights)\n",
    "            _dim_in_ensemble = self._adjust_loss_weights_and_ensemble_shape(\n",
    "                loss_weights=loss_weights,\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        else:\n",
    "            loss_weights = {\n",
    "                self.information_measure: torch.tensor(0.5),\n",
    "                \"BestHits\": torch.tensor(0.5),\n",
    "            }\n",
    "\n",
    "        ensemble_shape = tuple(ensemble_shape)\n",
    "\n",
    "        self.permutation = GeneralizedPermutation(\n",
    "            group_sizes=self.group_sizes,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            fixed_matchings=fixed_matchings,\n",
    "            mode=\"soft\",\n",
    "            **permutation_cfg,\n",
    "        )\n",
    "        self.ensemble_matrix_apply = EnsembleMatrixApply(group_sizes=self.group_sizes)\n",
    "        if self.information_measure == \"TwoBodyEntropy\":\n",
    "            self.information_loss = TwoBodyEntropyLoss()\n",
    "        elif self.information_measure == \"MI\":\n",
    "            self.information_loss = MILoss()\n",
    "        self.information_loss.register_buffer(\n",
    "            \"weight\", loss_weights[self.information_measure]\n",
    "        )\n",
    "\n",
    "        if similarity_kind == \"Blosum62\":\n",
    "            self.similarities = Blosum62Similarities(**similarities_cfg)\n",
    "        elif similarity_kind == \"Hamming\":\n",
    "            self.similarities = HammingSimilarities(**similarities_cfg)\n",
    "        self.best_hits = BestHits(\n",
    "            group_sizes=self.group_sizes,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            mode=\"soft\",\n",
    "            **best_hits_cfg,\n",
    "        )\n",
    "        self.best_hits.register_buffer(\"weight\", loss_weights[\"BestHits\"])\n",
    "        self.inter_group_loss = InterGroupLoss(\n",
    "            group_sizes=self.group_sizes, score_fn=self.inter_group_loss_score_fn\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def effective_loss_weights_(self) -> dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            self.information_measure: self.information_loss.weight,\n",
    "            \"BestHits\": self.best_hits.weight,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_cfg_and_ensemble_shape(\n",
    "        *,\n",
    "        ensemble_shape: list[int],\n",
    "        cfg: dict[str, Any],\n",
    "        param_name: str,\n",
    "        prev_dim_in_ensemble: int = -1,\n",
    "    ) -> int:\n",
    "        new_dim_in_ensemble = prev_dim_in_ensemble\n",
    "        if param_name in cfg:\n",
    "            param = scalar_or_1d_tensor(param=cfg[param_name], param_name=param_name)\n",
    "            cfg[param_name] = param\n",
    "            if param.ndim == 1:\n",
    "                ensemble_shape += list(param.shape)\n",
    "                new_dim_in_ensemble += 1\n",
    "                cfg[f\"{param_name}_dim_in_ensemble\"] = new_dim_in_ensemble\n",
    "\n",
    "        return new_dim_in_ensemble\n",
    "\n",
    "    def _adjust_loss_weights_and_ensemble_shape(\n",
    "        self,\n",
    "        *,\n",
    "        loss_weights: Optional[dict[str, Any]] = None,\n",
    "        ensemble_shape: list[int],\n",
    "        prev_dim_in_ensemble: int = -1,\n",
    "    ) -> int:\n",
    "        new_dim_in_ensemble = prev_dim_in_ensemble\n",
    "        if set(loss_weights) != self.loss_weights_keys:\n",
    "            raise ValueError(\n",
    "                \"`loss_weights` must be a dictionary with key set equal to \"\n",
    "                f\"{self.loss_weights_keys}.\"\n",
    "            )\n",
    "\n",
    "        loss_weight_entr = loss_weights[self.information_measure]\n",
    "        loss_weight_entr = scalar_or_1d_tensor(\n",
    "            param=loss_weight_entr,\n",
    "            param_name=f\"``loss_weights['{self.information_measure}']``\",\n",
    "        )\n",
    "        loss_weight_bh = loss_weights[\"BestHits\"]\n",
    "        loss_weight_bh = scalar_or_1d_tensor(\n",
    "            param=loss_weight_bh, param_name=\"``loss_weights['BestHits']``\"\n",
    "        )\n",
    "\n",
    "        if loss_weight_entr.ndim == 1 and loss_weight_bh.ndim == 1:\n",
    "            if loss_weight_entr.shape != loss_weight_bh.shape:\n",
    "                raise ValueError(\n",
    "                    f\"1D ``loss_weights['{self.information_measure}']`` and 1D \"\n",
    "                    \"``loss_weights['BestHits']`` must have the same shape.\"\n",
    "                )\n",
    "            ensemble_shape += list(loss_weight_entr.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        elif loss_weight_entr.ndim == 1 and loss_weight_bh.ndim == 0:\n",
    "            loss_weight_bh = loss_weight_bh.repeat(loss_weight_entr.shape[0])\n",
    "            ensemble_shape += list(loss_weight_entr.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        elif loss_weight_entr.ndim == 0 and loss_weight_bh.ndim == 1:\n",
    "            loss_weight_entr = loss_weight_entr.repeat(loss_weight_bh.shape[0])\n",
    "            ensemble_shape += list(loss_weight_bh.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        loss_weight_entr = self._reshape_ensemble_param(\n",
    "            param=loss_weight_entr,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            dim_in_ensemble=new_dim_in_ensemble,\n",
    "            n_dims_per_instance=0,\n",
    "            param_name=f\"``loss_weights['{self.information_measure}']``\",\n",
    "        )\n",
    "        loss_weight_bh = self._reshape_ensemble_param(\n",
    "            param=loss_weight_bh,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            dim_in_ensemble=new_dim_in_ensemble,\n",
    "            n_dims_per_instance=0,\n",
    "            param_name=\"``loss_weights['BestHits']``\",\n",
    "        )\n",
    "        loss_weights[self.information_measure] = loss_weight_entr\n",
    "        loss_weights[\"BestHits\"] = loss_weight_bh\n",
    "\n",
    "        return new_dim_in_ensemble\n",
    "\n",
    "    def _precompute_bh(self, x: torch.Tensor, y: torch.Tensor) -> None:\n",
    "        # Temporarily switch to hard BH\n",
    "        self.best_hits.hard_()\n",
    "        similarities_x = self.similarities(x)\n",
    "        self.register_buffer(\"_bh_hard_x\", self.best_hits(similarities_x))\n",
    "        similarities_y = self.similarities(y)\n",
    "        self.register_buffer(\"_bh_hard_y\", self.best_hits(similarities_y))\n",
    "\n",
    "        # Revert to soft (default) BH\n",
    "        self.best_hits.soft_()\n",
    "        self.register_buffer(\"_bh_soft_x\", self.best_hits(similarities_x))\n",
    "        similarities_y = self.best_hits.prepare_fixed(similarities_y)\n",
    "        self.register_buffer(\"_bh_soft_y\", self.best_hits(similarities_y))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        *,\n",
    "        x_perm_hard: Optional[torch.Tensor] = None,\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        mode = self.permutation.mode\n",
    "        assert mode == self.best_hits.mode\n",
    "\n",
    "        # Soft or hard permutations (list)\n",
    "        perms = self.permutation()\n",
    "        x_perm = self.ensemble_matrix_apply(x, mats=perms)\n",
    "\n",
    "        # Two-body entropy portion of the loss\n",
    "        loss_info = self.information_loss(x_perm, y)\n",
    "\n",
    "        # Best hits portion of the loss, with shortcut for hard permutations\n",
    "        if mode == \"soft\":\n",
    "            if x_perm_hard is not None:\n",
    "                x_perm = (x_perm_hard - x_perm).detach() + x_perm\n",
    "            similarities_x = self.similarities(x_perm)\n",
    "            bh_x = self.best_hits(similarities_x)\n",
    "        else:\n",
    "            bh_x = apply_hard_permutation_batch_to_similarity(\n",
    "                x=self._bh_hard_x, perms=perms\n",
    "            )\n",
    "        # Ensure comparisons are only hard-hard or soft-soft\n",
    "        loss_bh = self.inter_group_loss(bh_x, getattr(self, f\"_bh_{mode}_y\"))\n",
    "\n",
    "        return {\n",
    "            \"perms\": perms,\n",
    "            \"x_perm\": x_perm,\n",
    "            \"loss_info\": loss_info,\n",
    "            \"loss_bh\": loss_bh,\n",
    "        }\n",
    "\n",
    "    def soft_(self) -> None:\n",
    "        self.permutation.soft_()\n",
    "        self.best_hits.soft_()\n",
    "\n",
    "    def hard_(self) -> None:\n",
    "        self.permutation.hard_()\n",
    "        self.best_hits.hard_()\n",
    "\n",
    "    def _prepare_fit(self, x: torch.Tensor, y: torch.Tensor) -> DiffPASSResults:\n",
    "        # Validate inputs\n",
    "        self.validate_inputs(x, y)\n",
    "\n",
    "        # Precompute matrices of best hits\n",
    "        self._precompute_bh(x, y)\n",
    "\n",
    "        # Initialize DiffPassResults object\n",
    "        results = DiffPASSResults(\n",
    "            log_alphas=[],\n",
    "            soft_perms=[],\n",
    "            hard_perms=[],\n",
    "            soft_losses={self.information_measure: [], \"BestHits\": []},\n",
    "            hard_losses={self.information_measure: [], \"BestHits\": []},\n",
    "            hard_losses_identity_perm={\n",
    "                self.information_measure: None,\n",
    "                \"BestHits\": None,\n",
    "            },\n",
    "            soft_losses_identity_perm={\n",
    "                self.information_measure: None,\n",
    "                \"BestHits\": None,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Compute hard losses with identity permutation\n",
    "        self.hard_()\n",
    "        with torch.no_grad():\n",
    "            results.hard_losses_identity_perm[\n",
    "                self.information_measure\n",
    "            ] = self.information_loss(x, y).item()\n",
    "            results.hard_losses_identity_perm[\"BestHits\"] = self.inter_group_loss(\n",
    "                self._bh_hard_x, self._bh_hard_y\n",
    "            ).item()\n",
    "            results.soft_losses_identity_perm[\n",
    "                self.information_measure\n",
    "            ] = results.hard_losses_identity_perm[self.information_measure]\n",
    "            results.soft_losses_identity_perm[\"BestHits\"] = _dcc(\n",
    "                self.inter_group_loss(self._bh_soft_x, self._bh_soft_y)\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        results: DiffPASSResults,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        similarity_gradient_bypass: bool = False,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        # Initialize optimizer\n",
    "        optimizer_cls = getattr(torch.optim, optimizer_name)\n",
    "        optimizer_kwargs = (\n",
    "            {\"lr\": 1e-1} if optimizer_kwargs is None else deepcopy(optimizer_kwargs)\n",
    "        )\n",
    "        self.optimizer_ = optimizer_cls(self.parameters(), **optimizer_kwargs)\n",
    "\n",
    "        # Progress bar\n",
    "        pbar = range(epochs + 1)\n",
    "        if show_pbar:\n",
    "            pbar = tqdm(pbar)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        ## Gradient descent\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        x_perm_hard = None\n",
    "        with torch.set_grad_enabled(True):\n",
    "            self.optimizer_.zero_grad()\n",
    "            for i in pbar:\n",
    "                # Hard pass\n",
    "                self.hard_()\n",
    "                with torch.no_grad():\n",
    "                    epoch_results = self(x, y)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    loss_bh = epoch_results[\"loss_bh\"]\n",
    "                    if similarity_gradient_bypass:\n",
    "                        x_perm_hard = epoch_results[\"x_perm\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.log_alphas.append(\n",
    "                        [_dcc(log_alpha) for log_alpha in self.permutation.log_alphas]\n",
    "                    )\n",
    "                    results.hard_perms.append(\n",
    "                        [\n",
    "                            _dcc(perms_this_group).argmax(-1).to(torch.int16)\n",
    "                            for perms_this_group in perms\n",
    "                        ]\n",
    "                    )\n",
    "                    results.hard_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "                    results.hard_losses[\"BestHits\"].append(_dcc(loss_bh))\n",
    "\n",
    "                # Soft pass\n",
    "                if i < epochs or compute_final_soft:\n",
    "                    self.soft_()\n",
    "                    epoch_results = self(x, y, x_perm_hard=x_perm_hard)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    loss_bh = epoch_results[\"loss_bh\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.soft_perms.append(\n",
    "                        [_dcc(perms_this_group) for perms_this_group in perms]\n",
    "                    )\n",
    "                    results.soft_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "                    results.soft_losses[\"BestHits\"].append(_dcc(loss_bh))\n",
    "\n",
    "                    loss = (\n",
    "                        self.information_loss.weight * loss_info\n",
    "                        + self.best_hits.weight * loss_bh\n",
    "                    ).sum()\n",
    "                    loss.backward()\n",
    "                if i < epochs:\n",
    "                    self.optimizer_.step()\n",
    "                    self.optimizer_.zero_grad()\n",
    "                    if mean_centering:\n",
    "                        with torch.no_grad():\n",
    "                            for log_alpha in self.permutation.log_alphas:\n",
    "                                log_alpha[...] -= log_alpha.mean(\n",
    "                                    dim=(-1, -2), keepdim=True\n",
    "                                )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        similarity_gradient_bypass: bool = False,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        results = self._prepare_fit(x, y)\n",
    "        results = self._fit(\n",
    "            x,\n",
    "            y,\n",
    "            results,\n",
    "            epochs=epochs,\n",
    "            optimizer_name=optimizer_name,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            mean_centering=mean_centering,\n",
    "            similarity_gradient_bypass=similarity_gradient_bypass,\n",
    "            show_pbar=show_pbar,\n",
    "            compute_final_soft=compute_final_soft,\n",
    "        )\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class InformationAndMirrortree(Module, EnsembleMixin, DiffPASSMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        group_sizes: Iterable[int],\n",
    "        fixed_matchings: Optional[Sequence[Sequence[Sequence[int]]]] = None,\n",
    "        loss_weights: Optional[dict[str, Union[float, torch.Tensor]]] = None,\n",
    "        permutation_cfg: Optional[dict[str, Any]] = None,\n",
    "        information_measure: Literal[\"MI\", \"TwoBodyEntropy\"] = \"TwoBodyEntropy\",\n",
    "        similarity_kind: Literal[\"Hamming\", \"Blosum62\"] = \"Hamming\",\n",
    "        similarities_cfg: Optional[dict[str, Any]] = None,\n",
    "        intra_group_loss_score_fn: Optional[callable] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.group_sizes = tuple(s for s in group_sizes)\n",
    "        self.fixed_matchings = fixed_matchings\n",
    "        self.loss_weights = loss_weights\n",
    "        self.permutation_cfg = permutation_cfg\n",
    "        self.information_measure = information_measure\n",
    "        self.similarity_kind = similarity_kind\n",
    "        self.similarities_cfg = similarities_cfg\n",
    "        self.intra_group_loss_score_fn = intra_group_loss_score_fn\n",
    "\n",
    "        ensemble_shape = []\n",
    "        _dim_in_ensemble = -1\n",
    "\n",
    "        if permutation_cfg is None:\n",
    "            permutation_cfg = {}\n",
    "        else:\n",
    "            self.validate_permutation_cfg(permutation_cfg)\n",
    "            permutation_cfg = deepcopy(permutation_cfg)\n",
    "            _dim_in_ensemble = self._adjust_cfg_and_ensemble_shape(\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                cfg=permutation_cfg,\n",
    "                param_name=\"tau\",\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        self.effective_permutation_cfg_ = permutation_cfg\n",
    "\n",
    "        self.validate_information_measure(information_measure)\n",
    "        self.loss_weights_keys = {self.information_measure, \"Mirrortree\"}\n",
    "\n",
    "        self.validate_similarity_kind(similarity_kind)\n",
    "        if similarities_cfg is None:\n",
    "            similarities_cfg = {}\n",
    "        else:\n",
    "            self.validate_similarities_cfg(similarities_cfg)\n",
    "            similarities_cfg = deepcopy(similarities_cfg)\n",
    "        self.effective_similarities_cfg_ = similarities_cfg\n",
    "\n",
    "        if loss_weights is not None:\n",
    "            loss_weights = deepcopy(loss_weights)\n",
    "            _dim_in_ensemble = self._adjust_loss_weights_and_ensemble_shape(\n",
    "                loss_weights=loss_weights,\n",
    "                ensemble_shape=ensemble_shape,\n",
    "                prev_dim_in_ensemble=_dim_in_ensemble,\n",
    "            )\n",
    "        else:\n",
    "            loss_weights = {\n",
    "                self.information_measure: torch.tensor(0.5),\n",
    "                \"Mirrortree\": torch.tensor(0.5),\n",
    "            }\n",
    "\n",
    "        ensemble_shape = tuple(ensemble_shape)\n",
    "\n",
    "        self.permutation = GeneralizedPermutation(\n",
    "            group_sizes=self.group_sizes,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            fixed_matchings=fixed_matchings,\n",
    "            mode=\"soft\",\n",
    "            **permutation_cfg,\n",
    "        )\n",
    "        self.ensemble_matrix_apply = EnsembleMatrixApply(group_sizes=self.group_sizes)\n",
    "        if self.information_measure == \"TwoBodyEntropy\":\n",
    "            self.information_loss = TwoBodyEntropyLoss()\n",
    "        elif self.information_measure == \"MI\":\n",
    "            self.information_loss = MILoss()\n",
    "        self.information_loss.register_buffer(\n",
    "            \"weight\", loss_weights[self.information_measure]\n",
    "        )\n",
    "\n",
    "        if similarity_kind == \"Blosum62\":\n",
    "            self.similarities = Blosum62Similarities(**similarities_cfg)\n",
    "        elif similarity_kind == \"Hamming\":\n",
    "            self.similarities = HammingSimilarities(**similarities_cfg)\n",
    "        self.intra_group_loss = IntraGroupLoss(\n",
    "            group_sizes=self.group_sizes, score_fn=self.intra_group_loss_score_fn\n",
    "        )\n",
    "        self.intra_group_loss.register_buffer(\"weight\", loss_weights[\"Mirrortree\"])\n",
    "\n",
    "    @property\n",
    "    def effective_loss_weights_(self) -> dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            self.information_measure: self.information_loss.weight,\n",
    "            \"Mirrortree\": self.intra_group_loss.weight,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_cfg_and_ensemble_shape(\n",
    "        *,\n",
    "        ensemble_shape: list[int],\n",
    "        cfg: dict[str, Any],\n",
    "        param_name: str,\n",
    "        prev_dim_in_ensemble: int = -1,\n",
    "    ) -> int:\n",
    "        new_dim_in_ensemble = prev_dim_in_ensemble\n",
    "        if param_name in cfg:\n",
    "            param = scalar_or_1d_tensor(param=cfg[param_name], param_name=param_name)\n",
    "            cfg[param_name] = param\n",
    "            if param.ndim == 1:\n",
    "                ensemble_shape += list(param.shape)\n",
    "                new_dim_in_ensemble += 1\n",
    "                cfg[f\"{param_name}_dim_in_ensemble\"] = new_dim_in_ensemble\n",
    "\n",
    "        return new_dim_in_ensemble\n",
    "\n",
    "    def _adjust_loss_weights_and_ensemble_shape(\n",
    "        self,\n",
    "        *,\n",
    "        loss_weights: Optional[dict[str, Any]] = None,\n",
    "        ensemble_shape: list[int],\n",
    "        prev_dim_in_ensemble: int = -1,\n",
    "    ) -> int:\n",
    "        new_dim_in_ensemble = prev_dim_in_ensemble\n",
    "        if set(loss_weights) != self.loss_weights_keys:\n",
    "            raise ValueError(\n",
    "                \"`loss_weights` must be a dictionary with key set equal to \"\n",
    "                f\"{self.loss_weights_keys}.\"\n",
    "            )\n",
    "\n",
    "        loss_weight_entr = loss_weights[self.information_measure]\n",
    "        loss_weight_entr = scalar_or_1d_tensor(\n",
    "            param=loss_weight_entr,\n",
    "            param_name=f\"``loss_weights['{self.information_measure}']``\",\n",
    "        )\n",
    "        loss_weight_mt = loss_weights[\"Mirrortree\"]\n",
    "        loss_weight_mt = scalar_or_1d_tensor(\n",
    "            param=loss_weight_mt, param_name=\"``loss_weights['Mirrortree']``\"\n",
    "        )\n",
    "\n",
    "        if loss_weight_entr.ndim == 1 and loss_weight_mt.ndim == 1:\n",
    "            if loss_weight_entr.shape != loss_weight_mt.shape:\n",
    "                raise ValueError(\n",
    "                    f\"1D ``loss_weights['{self.information_measure}']`` and 1D \"\n",
    "                    \"``loss_weights['Mirrortree']`` must have the same shape.\"\n",
    "                )\n",
    "            ensemble_shape += list(loss_weight_entr.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        elif loss_weight_entr.ndim == 1 and loss_weight_mt.ndim == 0:\n",
    "            loss_weight_mt = loss_weight_mt.repeat(loss_weight_entr.shape[0])\n",
    "            ensemble_shape += list(loss_weight_entr.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        elif loss_weight_entr.ndim == 0 and loss_weight_mt.ndim == 1:\n",
    "            loss_weight_entr = loss_weight_entr.repeat(loss_weight_mt.shape[0])\n",
    "            ensemble_shape += list(loss_weight_mt.shape)\n",
    "            new_dim_in_ensemble += 1\n",
    "        loss_weight_entr = self._reshape_ensemble_param(\n",
    "            param=loss_weight_entr,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            dim_in_ensemble=new_dim_in_ensemble,\n",
    "            n_dims_per_instance=0,\n",
    "            param_name=f\"``loss_weights['{self.information_measure}']``\",\n",
    "        )\n",
    "        loss_weight_mt = self._reshape_ensemble_param(\n",
    "            param=loss_weight_mt,\n",
    "            ensemble_shape=ensemble_shape,\n",
    "            dim_in_ensemble=new_dim_in_ensemble,\n",
    "            n_dims_per_instance=0,\n",
    "            param_name=\"``loss_weights['Mirrortree']``\",\n",
    "        )\n",
    "        loss_weights[self.information_measure] = loss_weight_entr\n",
    "        loss_weights[\"Mirrortree\"] = loss_weight_mt\n",
    "\n",
    "        return new_dim_in_ensemble\n",
    "\n",
    "    def _precompute_similarities(self, x: torch.Tensor, y: torch.Tensor) -> None:\n",
    "        self.register_buffer(\"_similarities_hard_x\", self.similarities(x))\n",
    "        self.register_buffer(\"_similarities_hard_y\", self.similarities(y))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        *,\n",
    "        x_perm_hard: Optional[torch.Tensor] = None,\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        mode = self.permutation.mode\n",
    "\n",
    "        # Soft or hard permutations (list)\n",
    "        perms = self.permutation()\n",
    "        x_perm = self.ensemble_matrix_apply(x, mats=perms)\n",
    "\n",
    "        # Two-body entropy portion of the loss\n",
    "        loss_info = self.information_loss(x_perm, y)\n",
    "\n",
    "        # Mirrortree portion of the loss, with shortcut for hard permutations\n",
    "        if mode == \"soft\":\n",
    "            if x_perm_hard is not None:\n",
    "                x_perm = (x_perm_hard - x_perm).detach() + x_perm\n",
    "            similarities_x = self.similarities(x_perm)\n",
    "        else:\n",
    "            similarities_x = apply_hard_permutation_batch_to_similarity(\n",
    "                x=self._similarities_hard_x, perms=perms\n",
    "            )\n",
    "        # Ensure comparisons are only hard-hard or soft-soft\n",
    "        loss_mt = self.intra_group_loss(\n",
    "            similarities_x, getattr(self, f\"_similarities_hard_y\")\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"perms\": perms,\n",
    "            \"x_perm\": x_perm,\n",
    "            \"loss_info\": loss_info,\n",
    "            \"loss_mt\": loss_mt,\n",
    "        }\n",
    "\n",
    "    def soft_(self) -> None:\n",
    "        self.permutation.soft_()\n",
    "\n",
    "    def hard_(self) -> None:\n",
    "        self.permutation.hard_()\n",
    "\n",
    "    def _prepare_fit(self, x: torch.Tensor, y: torch.Tensor) -> DiffPASSResults:\n",
    "        # Validate inputs\n",
    "        self.validate_inputs(x, y)\n",
    "\n",
    "        # Precompute matrices of Mirrortree\n",
    "        self._precompute_similarities(x, y)\n",
    "\n",
    "        # Initialize DiffPassResults object\n",
    "        results = DiffPASSResults(\n",
    "            log_alphas=[],\n",
    "            soft_perms=[],\n",
    "            hard_perms=[],\n",
    "            soft_losses={self.information_measure: [], \"Mirrortree\": []},\n",
    "            hard_losses={self.information_measure: [], \"Mirrortree\": []},\n",
    "            hard_losses_identity_perm={\n",
    "                self.information_measure: None,\n",
    "                \"Mirrortree\": None,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Compute hard losses with identity permutation\n",
    "        self.hard_()\n",
    "        with torch.no_grad():\n",
    "            results.hard_losses_identity_perm[\n",
    "                self.information_measure\n",
    "            ] = self.information_loss(x, y).item()\n",
    "            results.hard_losses_identity_perm[\"Mirrortree\"] = self.intra_group_loss(\n",
    "                self._similarities_hard_x, self._similarities_hard_y\n",
    "            ).item()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        results: DiffPASSResults,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        similarity_gradient_bypass: bool = False,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        # Initialize optimizer\n",
    "        optimizer_cls = getattr(torch.optim, optimizer_name)\n",
    "        optimizer_kwargs = (\n",
    "            {\"lr\": 1e-1} if optimizer_kwargs is None else deepcopy(optimizer_kwargs)\n",
    "        )\n",
    "        self.optimizer_ = optimizer_cls(self.parameters(), **optimizer_kwargs)\n",
    "\n",
    "        # Progress bar\n",
    "        pbar = range(epochs + 1)\n",
    "        if show_pbar:\n",
    "            pbar = tqdm(pbar)\n",
    "\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        ## Gradient descent\n",
    "        # ------------------------------------------------------------------------------------------\n",
    "        x_perm_hard = None\n",
    "        with torch.set_grad_enabled(True):\n",
    "            self.optimizer_.zero_grad()\n",
    "            for i in pbar:\n",
    "                # Hard pass\n",
    "                self.hard_()\n",
    "                with torch.no_grad():\n",
    "                    epoch_results = self(x, y)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    loss_mt = epoch_results[\"loss_mt\"]\n",
    "                    if similarity_gradient_bypass:\n",
    "                        x_perm_hard = epoch_results[\"x_perm\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.log_alphas.append(\n",
    "                        [_dcc(log_alpha) for log_alpha in self.permutation.log_alphas]\n",
    "                    )\n",
    "                    results.hard_perms.append(\n",
    "                        [\n",
    "                            _dcc(perms_this_group).argmax(-1).to(torch.int16)\n",
    "                            for perms_this_group in perms\n",
    "                        ]\n",
    "                    )\n",
    "                    results.hard_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "                    results.hard_losses[\"Mirrortree\"].append(_dcc(loss_mt))\n",
    "\n",
    "                # Soft pass\n",
    "                if i < epochs or compute_final_soft:\n",
    "                    self.soft_()\n",
    "                    epoch_results = self(x, y, x_perm_hard=x_perm_hard)\n",
    "                    loss_info = epoch_results[\"loss_info\"]\n",
    "                    loss_mt = epoch_results[\"loss_mt\"]\n",
    "                    perms = epoch_results[\"perms\"]\n",
    "                    results.soft_perms.append(\n",
    "                        [_dcc(perms_this_group) for perms_this_group in perms]\n",
    "                    )\n",
    "                    results.soft_losses[self.information_measure].append(\n",
    "                        _dcc(loss_info)\n",
    "                    )\n",
    "                    results.soft_losses[\"Mirrortree\"].append(_dcc(loss_mt))\n",
    "\n",
    "                    loss = (\n",
    "                        self.information_loss.weight * loss_info\n",
    "                        + self.intra_group_loss.weight * loss_mt\n",
    "                    ).sum()\n",
    "                    loss.backward()\n",
    "                if i < epochs:\n",
    "                    self.optimizer_.step()\n",
    "                    self.optimizer_.zero_grad()\n",
    "                    if mean_centering:\n",
    "                        with torch.no_grad():\n",
    "                            for log_alpha in self.permutation.log_alphas:\n",
    "                                log_alpha[...] -= log_alpha.mean(\n",
    "                                    dim=(-1, -2), keepdim=True\n",
    "                                )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        *,\n",
    "        epochs: int = 1,\n",
    "        optimizer_name: Optional[str] = \"SGD\",\n",
    "        optimizer_kwargs: Optional[dict[str, Any]] = None,\n",
    "        mean_centering: bool = True,\n",
    "        similarity_gradient_bypass: bool = False,\n",
    "        show_pbar: bool = True,\n",
    "        compute_final_soft: bool = True,\n",
    "    ) -> DiffPASSResults:\n",
    "        results = self._prepare_fit(x, y)\n",
    "        results = self._fit(\n",
    "            x,\n",
    "            y,\n",
    "            results,\n",
    "            epochs=epochs,\n",
    "            optimizer_name=optimizer_name,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            mean_centering=mean_centering,\n",
    "            similarity_gradient_bypass=similarity_gradient_bypass,\n",
    "            show_pbar=show_pbar,\n",
    "            compute_final_soft=compute_final_soft,\n",
    "        )\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_num_correct_matchings(\n",
    "    results: DiffPASSResults,\n",
    "    *,\n",
    "    index_based: bool,\n",
    "    x_seqs: Optional[list[list[tuple]]] = None,\n",
    "    y_seqs: Optional[list[list[tuple]]] = None,\n",
    "    xy_seqs: Optional[list[dict[str, int]]] = None,\n",
    ") -> list[int]:\n",
    "    \"\"\"Compute the number of matchings that are 'correct' at each step of the optimization.\n",
    "    'Correct' means that they are present in the original paired MSAs, assumed to be the\n",
    "    ground truth.\n",
    "\n",
    "    If `index_based` is True, then the matchings are assumed to be represented as range indices\n",
    "    for faster computation, and the `x_seqs`, `y_seqs`, and `xy_seqs` arguments are ignored.\n",
    "    \"\"\"\n",
    "    correct = []\n",
    "    if index_based:\n",
    "        for perms in results.hard_perms:\n",
    "            correct_this_step = 0\n",
    "            for perm_this_group in perms:\n",
    "                n_seqs_this_group = perm_this_group.shape[-1]\n",
    "                correct_this_group = perm_this_group == torch.arange(n_seqs_this_group)\n",
    "                correct_this_group = correct_this_group.sum().item()\n",
    "                correct_this_step += correct_this_group\n",
    "            correct.append(correct_this_step)\n",
    "    else:\n",
    "        for perms in results.hard_perms:\n",
    "            correct_this_perm = 0\n",
    "            for (\n",
    "                perm_this_group,\n",
    "                x_seqs_this_group,\n",
    "                y_seqs_this_group,\n",
    "                xy_seqs_this_group,\n",
    "            ) in zip(perms, x_seqs, y_seqs, xy_seqs):\n",
    "                _xy_seqs_this_group = xy_seqs_this_group.copy()\n",
    "                x_seqs_this_group_perm = [\n",
    "                    x_seqs_this_group[idx] for idx in perm_this_group\n",
    "                ]\n",
    "                for x_seq, y_seq in zip(x_seqs_this_group_perm, y_seqs_this_group):\n",
    "                    xy_key = f\"{x_seq}:{y_seq}\"\n",
    "                    if _xy_seqs_this_group.get(xy_key, 0) > 0:\n",
    "                        _xy_seqs_this_group[xy_key] -= 1\n",
    "                        correct_this_perm += 1\n",
    "\n",
    "            correct.append(correct_this_perm)\n",
    "\n",
    "    return correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
